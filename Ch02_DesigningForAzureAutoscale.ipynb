{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Azure Autoscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000002.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we will cover designing for Azure autoscale and see how you can benefit from using the different available methods. In fact, proper use of an autoscale method can have a positive financial impact for your company and can greatly reduce manual operations that can sometimes lead to human mistakes or incorrectly balanced systems. We will understand the difference between vertical and horizontal scaling and under which circumstances you should use one or the other. For example, these two concepts are different, whether you are working with a single virtual machine or a virtual machine scale set. For a good understanding of how autoscaling works, it is very important to understand the key differences. In order to do so, we will see a demonstration on how to scale up our virtual machine from the Azure platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000003.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to work with autoscaling rules. This is where automation comes in place. We'll learn how to configure rules to autoscale an environment to provide a healthy end‑user experience when accessing your resources. We'll see how with the use of metrics, such as CPU or memory usage, you can easily configure rules to automate scaling up or down your environment. Then, we'll jump to creating a virtual machine scale set. We will learn how it can provide high availability and improve performance for your users. This is a critical concept when thinking about redundancy within the Azure platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000004.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will take a look at autoscaling rules and actually enable autoscale on a virtual machine scale set. We will then take a look on how autoscaling can be used when working with the Azure App Service. We'll do pretty much the same thing as when working with virtual machine scale sets and see the similarities when configuring autoscaling rules. We will end this module with a wrap up of what we covered so far while taking a look at the scalability options using Azure Functions and how it can help deliver serverless applications to your audience. Now, let's move to the next clip and learn about key differences between vertical and horizontal scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Understanding Vertical Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000006.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of elastic computing is something we hear more and more about, and it is a benefit I think cloud computing made available to us. Those of you working in the IT field for the last decades will remember how deploying a cluster resource to provide high availability to your end users could be complicated. Let's say you have a three‑node cluster for a web application and you lose one of the servers. Well, you have to build a new server from scratch, remove the old one, add the new want to the cluster, and make sure everything is back to normal. This is time‑consuming and, like I mentioned earlier, can lead to human mistakes.\n",
    "\n",
    "Then came virtual machines, which kind of made things easier for us. We no longer needed to work with physical components, drivers, and compatibility lists. But the real great thing is cloud computing and the possibility of automating virtual machines and application deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000007.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Azure platform, you can use vertical or horizontal scaling when deploying services. But first, what is autoscale? Well, autoscale allows you to evenly distribute resources to your applications. If more resources are required, new resources are added. If any resources are idle, it will be removed. This behavior can enhance the end user experience as it increases or decreases following the end user's workload. This can be modified any time during the lifecycle of your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000008.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like I mentioned earlier, you can scale your environment in two different ways. You can do vertical scaling, or you can do horizontal scaling. Vertical scaling is typically used with virtual machines. Let's say you have four VMs running your business application. If you wanted to do vertical scaling, then you would either scale up or down. You would keep the same number of the VMs, but you could scale up or down memory, CPU, or disk space depending on your needs. For example, you may be running a single virtual machine in development. Let's say it is a standard general purpose VM size with one CPU and 1GB of RAM. This server needs to accommodate more users, and you are required to scale up memory to a total of 4GB. You could simply plan a maintenance window and vertically scale the server to the new VM size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000009.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some limitations as this method is dependent on the hardware available. This needs to be put under consideration depending on your geographical location as it may vary from one region to another. Also this method typically requires the virtual machine to be restarted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000010.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've covered scaling up a virtual machine, but other services can also be scaled up or down depending on your needs. For example, if you are working with Azure SQL, you can change a plan for your data transaction units or DTUs to a bigger plan if needed. If you're working with web applications, you can also scale the app service plan to better fit your needs. Now enough said. Let's see how this can be done from the Azure portal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Vertical Scaling from the Azure Portal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "In this demo, we will see out to scale up a virtual machine to a new VM size using the Azure portal. I'm logged in to the Azure portal, and I'm in the Virtual machines section. I already deployed a VM, vm01. This is a virtual machine I will be scaling up. I'll just click on the virtual machine to get an overview of its actual parameters. This is a Windows Server 2019, and the size is Standard B1s with 1 virtual CPU and 1 GB of memory. Let's copy the public IP address and connect to the server using a remote desktop connection. Best practices will dictate to use a management VM from which you can connect to your internal resources using the internal network. Exposing your virtual machine to the public network comes with security risk. If you do so, make sure your network security rules are correctly configured. I'll just enter the password for the admin account and accept/trust the server certificate. Once connected to the server, I'll open a command prompt and run the system in full command to confirm resources allocated to this machine. This will take a couple seconds to complete. We can see the server as 1 GB of memory allocated. Now, let's scale up this VM. I'll switch back to the Azure portal, and always from the properties of the virtual machine I'll select Size. From here, I can scale to many different sizes. I'll select B1ms to scale up to 2 GB of memory. The deployment is now started. Let's switch back to the virtual machine. We can see the server reboots to change its VM size. We'll leave it a couple seconds for this to complete. We can confirm from the Azure portal that the VM has changed by clicking the notifications icon. I am now running a B1ms with 2 GB of memory. Back to the server. Again, from the command prompt, I'll run the system in full command. We can see the amount of memory allocated has changed to 2 GB. This is the end of the demo on how to scale up a single virtual machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Understanding Horizontal Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000012.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen that vertical scaling is a manual process, and in some cases might cause a disruption of the service while you are scaling up the environment. The other option is horizontal scaling. Horizontal scaling is a more flexible option where you do not scale up or down your environment, but either scale out, or increase, or scale in, or decrease, the number of virtual machine instances you are running. Based on metrics such as CPU or memory usage, you can set up rules to deploy as many virtual machines as you need to service your application. The nice thing about horizontal scaling is that your application will continue to run while your virtual machines are being populated. Later on, when the application becomes less in demand, resources are deallocated, again, without any interruption. All of this is done by the use of autoscaling rules. An autoscaling rule determines at which threshold a new VM should be provisioned _____ when a running VM should be deallocated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000013.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you are running a single virtual machine and have configured an autoscaling rule with the following para meters: scale out when the average CPU is over 80% for 10 minutes. If your virtual machine is running over 80% of average CPU for the 10‑minute period of time that is defined in the rule, then a new VM will be provisioned and added to your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000014.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what happens when there are less connections to your resources? That's where you will also need to create a scaling rule. It could look like this, scaling when the average CPU is less than 30% for 15 minutes. You might ask how can your client connect to the new virtual machine?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000015.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the environment know new resources have been added? Typically, this is done by the use of a load balancer. The load balancer will be aware if your virtual machine is not available and will route traffic towards this new resource. The same is true when resources are no longer available. Load balancing will be covered in more details in the module, Designing for Network Redundancy, later on in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing Autoscaling Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000017.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a closer look at autoscaling rules. This is a very important concept when planning for high availability whenever you are deploying a virtual machine scale set our web applications using the App Service. In fact, when your autoscale settings are correctly defined, it will guarantee you have the right amount of resources to support the load of your application. This brings a lot of flexibility or elasticity to the expansion of your applications.\n",
    "\n",
    "When you can't figure autoscaling rules, you will need to determine the minimum, maximum, and default virtual machine count. For example, for a set of virtual machines, you could define two as a minimum. This kind of brings high availability right here from the start. Then the maximum VM count could be based on your budget, let's say six. You could then set the default to be three. Just make sure the default and minimum settings are not conflicting. You cannot create an autoscaling rule with a value for the default lowered than the minimum instances count required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000018.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoscale can also be triggered depending on metrics that you define. Such metrics could be processor or memory usage for example. This is known as a regular profile.\n",
    "\n",
    "You could also use fixed date profile where autoscaling is scheduled and triggered on a precise date and time. Let's say your company is announcing a new product on a specific date, and you want to make sure all the resources are available before clients start rushing in.\n",
    "\n",
    "The last type of profile is a recurrence profile. A common scenario will be a web application where higher than normal usage is to be expected over the weekends. You could configure the autoscale settings to scale out your web application from Friday until Sunday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000019.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, you can also create an autoscaling rule based on metrics. Metrics can be anything from disk usage, CPU, or memory. You can also scale based on network with metrics such a bytes received our bytes sent. There is a lot of parameters available that will help you out configuring your own autoscaling rules that can be based sometimes on very special needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000020.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set autoscaling rules between multiple profiles, each with different rules for different metrics. So what happens when you are in such a situation where your scale set is submitted to multiple autoscaling profiles? Well, when the autoscale job runs, it first checks if any fixed date profiles exist that need to be run at this time. If so, it will execute the fixed date profile. If not, it checks if a recurrence profile exists. Again, if this is true, it will run the recurrence Profile. Finally, if none of the previous profiles are found, your autoscale job will run the regular profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000021.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this running without you knowing about it might be a concern. You might decide on monitoring autoscale actions inside your Azure environment. This can be done in different ways. First, an email can be sent to a distribution group or any valid email address you choose. You could also use Webhooks to send any Azure alerts to other systems handling different services, such as sending SMS to a support team. From the Azure portal, you can also browse through the Azure Monitor blade to see the autoscale status of all your applications. The Azure Monitor section is a great place to gather centralized information about the old environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Autoscaling Virtual Machine Scale Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "In this demo, we will see how to create a virtual machine scale set and configure an autoskill profile usually the Microsoft Azure portal. From the Azure portal, click on Create a resource. Search for virtual machine scale set. If we take a look at the overview, we read that Azure virtual machine scale sets let you create and manage a group of identical load balance VMs. The number of VM instances can automatically increase or decrease in response to demand or a defined schedule. This is exactly what we are looking for, so let's click on Create to go on with the creation process. Here we need to provide a name for the virtual machine scale set. I'll call it VMScaleSet1. Under Operating system disk image, I'll select a CentOS‑based virtual machine. Subscription information is correct. I will create a new resource group and call it VMScaleSet‑RG. This resource group will hold objects related to my virtual machine scale set. You can choose an already existing resource group if you want. Location will be East US 2, and I will not define any availability zone. Now let's provide username and password for the admin account. Under the Instances section, I will keep the default of two instances, and I will change the instance size to keep the deployment costs as low as possible. I also like the B1ls VM size, which will be more than enough for the purposes of this demonstration. Let's drill down to the Scaling section. I could enable scaling right away during the deployment of my virtual mission scale set by clicking the Enabled radio button. From here, I could set the minimum and maximum number of VMS. I could also set scale out and scale in rules based on CPU metrics. Let's disable autoscale for now as we will configure this feature in a few minutes. Under the Networking section, I will select Load balancer as a load balancing option. I must provide the public IP address name, which will be VMScaleSetIP. Under Domain name label, I will need to find a name that is available. In this case, I will use vmscaleset. Now let's configure our virtual network. I can create a new one by clicking on Create new. I'll give it a name, ScaleSet‑VNET, and I will keep the defaults for the address space and subnets. I will keep the rest of the configuration with the default settings and click on Create to start a virtual machine scale set deployment. This will take a couple minutes as different objects needs to be created, such as the virtual machines, the load balancer, and a virtual network. The deployment is now complete. I'll switch to the resource groups and select VMScaleSet‑RG, which is the new resource group I just created. We can see the different objects it contains that are required for the VM scale set to work. We can see the virtual network, the virtual machine scale set, the load balancer, the network security group, and, lastly, the public IP address. Let's select a virtual machine scale set. Here we get an overview of VMScaleSet1. Under Status, we can see two out of two succeeded, so we should see two virtual machines running. Let's confirm this by clicking Instances. Here we can see both instances running. So far, we are good. Now let's see how to configure autoscale for this virtual machine scale set. To do so, click on Scaling. From the Scaling section, I could choose manual scale and simply modify the instance count. The custom autoscale option will let us define autoscale based on the schedule or any metrics. I'll select this option. Keep the default autoscale setting name, or change it to something more intuitive. The scale mode will be scaled based on a metric. We can see here the red exclamation mark. This informs us that there are no metric rules defined. We will fix that right away by clicking Add a rule. We will keep the time aggregation to average, as well as the defaults for the metric namespace and metric name. If you want to explore the different metrics available, click on the arrow to see the list. Select a metric that will best fit your needs when building your autoscaling rule. If I drill down to the bottom, I can select the operator whether I want greater than or equal to. I will select greater than or equal to. I must now set a value for the metric. Let's say 80%. The duration in minutes should be 15 minutes. Under the Action section, I'll keep the operation and instance count to their default settings, which is increase count by one. The cooldown period is the amount of time the autoscale service will wait after a scale operation was performed before attempting to scale again. This leaves time for the metrics to stabilize. Once you're good with the rule in place, click on Add. We can now review the rule. Notice the blue exclamation mark. It is recommended to have at least one scaling rule. So far, the autoscale configuration will scale out by one instance whenever the autoscale service will verify the rule and see it meets the criteria. Adding a scale in rule will make sure your environment falls back to use only the resources that are required for your application. You can do so by creating a new rule as we just did. But this time the scaling rule will decrease the instance count whenever the metrics we define are met. This is the end of the demo on how to enable autoscaling rules for a virtual machine scale set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Scalability with Azure App Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "In the next demo, we will learn about scalability with Azure App Service. We can do almost the same thing with the app service as with a virtual machine scale set. Autoscaling works pretty much the same way. Let's go to the App Services section and click on Create app service. I'll create a new resource group called AppSVC. I must now provide a name for my instance. This needs to be unique under the .azurewebsites .NET environment. I'll choose appsvcweb. It is available, so l'll use this one. Runtime stack will be .NET Core 3.0, and the operating system will be Windows. Select your region, in my case East US 2. Now let's take a look at a different app service plans available for the East US 2 region. If I click on Change size, it will bring me to the different pricing tiers available. Let's look at the Dev/Test pricing tier. The F1 and D1 options do not offer any scaling. B1 offers manual scaling to up to three instances. To be able to use the autoscale feature, I will need to select the production pricing tier. All of the different options here offers autoscale. For example, the S1 will allow autoscale up to 10 instances, while the others will offer up to 20 instances. I will select S1 and click Apply. Let's review our selection by clicking on review and create. Once we're okay with configurations, click on Create. This will take a couple seconds for everything to be created inside the Azure environment. The deployment is now complete. Let's go back to the resource groups and select AppSvc. I can see the different objects that were deployed. Let's select the app service. Search for the scale out section. This is the exact same thing as with virtual machine scale sets. The big difference here is a scale up link. From here, you can change your app service pricing tier. You could decide to move from S1 to P1V2, providing your environment with more resources. This completes this demo on scalability with Azure App Services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Functions Hosting Plans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000023.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last section of this module will cover Azure Functions Hosting Plans. If you've been working with different cloud platforms, you've certainly heard about serverless infrastructure. Such technologies provide you with the ability to develop and execute code using serverless applications without worrying about the outlying servers actually running your pieces of code. Microsoft Cloud Services offers such a serverless infrastructure by the use of Azure Functions. A function will run when a specific event is triggered. It could be a schedule responding to our message or an HTTP request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000024.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical use of Functions varies from processing bulk data and working with the Internet of Things, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000025.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use Azure Functions to dynamically scale your applications by setting the functions to respond to events that you specify. This is greatly efficient when orchestrating tasks and to reach and high level of automation as well. When building a Function app, you process just like you would when creating any other resource. You create or select a resource group, choose a platform, whether it is Windows or Linux. It's almost the same as creating a web app. The main consideration here that you need to think about is the hosting plan you will be selecting. In fact, when you create a new Function app, you must choose between three different options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000026.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plan, which is also the default that is proposed, is the Consumption plan. This plan will provide all the compute power you need, and the billing is based for the period of time when your code is actually running. What it means is that resources are dynamically allocated to respond to your application load. The benefit of this plan is that you don't need to bother with any auto‑scaling configuration, you only pay for what you use.\n",
    "\n",
    "The second option is a Premium plan. This feature lets you define a specific number of instances that will be running backstage at all time, ready to kick in whenever new resources are necessary. Instances being already online when your function runs, if additional resources are required, the response will be immediate. Using this plan, you will pay for both pre‑warmed instances and any other instances running to support your application.\n",
    "\n",
    "The App Service plan is the third option you can choose from. This one is pretty simple as it lets you run Functions the same way you would run web apps. If you are already using the App Service, you can run your functions on the same plan as your applications at no cost. Finally, Azure Function app can provide high availability to your application and is definitely worth taking a look into it. Keep in mind to choose the host plan that best fit your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Module Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000027.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recap on what we covered so far throughout this module. We started with key differences between vertical and horizontal scaling. Vertical scaling is typically done on virtual machines to add or remove resources such as CPU, memory, or disk space. It can also be done when using the App Service or Azure SQL plans. It is also a manual process and in some cases can cause downtime to your environment while the scaling process is underway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/agungwahyudi-public-files/azure_high_availability-2-000028.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then covered horizontal scaling. This is an autoscaling method where you will really see the most important benefits as no downtime is to be expected. Using only the resources that you need to support the workload of your applications can have a significant positive financial impact on your company's budget. Horizontal scaling is typically used with virtual machine scale sets or when using the Azure App Service. This method also provides you with the availability to build large‑scale services. We've seen how to design autoscaling rules and in which order autoscaling profiles are being applied. We've learned our rules are based on metrics to trigger an action for either skilling in or out resources. Then, from the Azure portal, we deployed a virtual machine scale set and worked with autoscaling rules. We realized how simple it can be to provide 24 hours high availability to any of our web applications. We completed this module with Azure Functions. We got an overview of serverless applications and how these small pieces of code can be run without you having to think about the old infrastructure we needed. This is already the end of this module on Designing for Azure Autoscale. Let's jump to our next topic. Designing for Storage High Availability."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
